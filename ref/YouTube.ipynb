{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d71ce35-f608-4065-a7e6-7d0fc0682396",
   "metadata": {},
   "source": [
    "# Get info from YouTube via YouTube DATA API\n",
    "\n",
    "Date: 2024/10/18\n",
    "\n",
    "Part of the Python scripts were generated by gpt-4o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ede539-3460-419e-898d-d80b12e09dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# My YouTube channel's ID\n",
    "CHANNEL_ID = \"UC6VcKqPLItoVPsuH-T8HKtQ\"\n",
    "\n",
    "API_KEY = os.environ[\"YOUTUBE_API_KEY\"]\n",
    "len(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4906435e-0bca-43e7-8ce0-bb97984b737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bjNSUi2Oawk',\n",
       " '1yXJCsx69_0',\n",
       " 'hELRpxUZ1hc',\n",
       " 'HVZwn9KIWiU',\n",
       " 'W05RhCUnlH4',\n",
       " 'ICZHSJ5eQME',\n",
       " 'wX6leJTcHME',\n",
       " 'MoSrWDInzIg',\n",
       " '1Ucw4LMh3Ow',\n",
       " 'OWIU_BMA92s',\n",
       " 'bS-bzMsygZQ',\n",
       " 'e6F0C5PsM-8',\n",
       " 'WKvi7je3oDE',\n",
       " 'N-dCsRtM6n0',\n",
       " '9N4XoviSjys',\n",
       " 'xugC3eSykPA',\n",
       " 'zQEbJUg8r9o',\n",
       " '1xmiIczxZqo',\n",
       " 'fQNP2FG3s7k',\n",
       " 'DVG4slg7Q_Y',\n",
       " 'F15Zp4pqwVk',\n",
       " 'C_qCqOBFJzs',\n",
       " 'fLw5PB_CiDo',\n",
       " 'VYyuJVpb2LU',\n",
       " 'b3r3MgwXIK0',\n",
       " 'U4oGypuHEh0',\n",
       " 'zWdhYGzhVPs',\n",
       " 'vBHXwXxKi4s',\n",
       " 'BFTbxZobyvY',\n",
       " 'IXSC8B0Yoos',\n",
       " 'xICYinJU3u4',\n",
       " '3EMcrRJ446w',\n",
       " 'NR9jN1WamqI',\n",
       " 'mACBBLufDp0',\n",
       " 'CTrM93eaq1s',\n",
       " 'ytygJGUO5nM',\n",
       " 'um-spiRzK4k',\n",
       " 'gcNkXm_A9H8',\n",
       " 'cl6UpGPZEys',\n",
       " 'Is45dRC3fNM',\n",
       " '5SQ1QVdskcI',\n",
       " '2z0K-X5a5Ss',\n",
       " '2AjkpGLnm74',\n",
       " '0X4c5gxU6-A',\n",
       " 'UvSJ3fOOCXc',\n",
       " 'RFJgpf7kdJA',\n",
       " '4BaBL-gmQBk',\n",
       " 'RV7oED41P2w',\n",
       " 'wbkjt2Bl5TY',\n",
       " 'd6OYSllaVEs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_video_ids_from_channel(channel_id, api_key, max_results=50):\n",
    "    url = (\n",
    "        f\"https://www.googleapis.com/youtube/v3/search\"\n",
    "        f\"?key={api_key}&channelId={channel_id}&part=snippet,id\"\n",
    "        f\"&order=date&type=video&maxResults={max_results}\"\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    data = response.json()\n",
    "    video_ids = [\n",
    "        item['id']['videoId'] for item in data.get('items', []) if 'videoId' in item['id']\n",
    "    ]\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "MAX_RESULTS = 50\n",
    "\n",
    "video_ids = get_video_ids_from_channel(CHANNEL_ID, API_KEY, MAX_RESULTS)\n",
    "video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ce92b1-66cd-4e2c-a691-f30db3c3c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Video ID: bjNSUi2Oawk\n",
      "\n",
      "Description:\n",
      "https://github.com/araobp/virtual-showroom\n",
      "\n",
      "Processing Procedure\n",
      "- The panorama image, along with a text prompt, is sent to the OpenAI API.\n",
      "- The text returned from OpenAI is displayed in a text area, and it is also sent to OpenAI's TTS (text-to-speech) API. After receiving the speech data, it is played within Unity.\n",
      "- The LLM also judges mood of the image.\n",
      "\n",
      "Parts\n",
      "- All the models generated with MFPB2\n",
      "- Animation clips are my originals.\n",
      "- LLM: OpenAI gpt-4o-mini\n",
      "- TTS: OpenAI tts\n",
      "- Pictures: my original ones and the three other pictures from PolyHaven\n",
      "- Compact RAG: my original implementation.\n",
      "\n",
      "# Video ID: 1yXJCsx69_0\n",
      "\n",
      "Description:\n",
      "https://github.com/araobp/virtual-showroom\n",
      "\n",
      "Processing Procedure\n",
      "- The robot captures the scene in front of it using a camera (Unity's Camera).\n",
      "- The captured image, along with a text prompt, is sent to the OpenAI API.\n",
      "- The text returned from OpenAI is displayed in a text area, and it is also sent to OpenAI's TTS (text-to-speech) API. After receiving the speech data, it is played within Unity.\n",
      "\n",
      "Parts\n",
      "- The robot: the ThirdPerson model from Unity's Starter Assets, modified with Blender a little bit.\n",
      "- Animation clips: Mixamo\n",
      "- LLM: OpenAI gpt-4o-mini\n",
      "- TTS: OpenAI tts\n",
      "- Pictures: the all pictures from ISO Republic\n",
      "- BGM: CC0 music from Wikipedia\n",
      "\n",
      "# Video ID: hELRpxUZ1hc\n",
      "\n",
      "Description:\n",
      "Walk-through Face Recognition scene made with Blender.\n",
      "\n",
      "This is a demo animation to show that what I can do as a MVP developer for marketing new technologies such as AI.\n",
      "\n",
      "https://github.com/araobp/blender-3d\n",
      "\n",
      "[Credits]\n",
      "\n",
      "All the characters are made with MPFB2.\n",
      "\n",
      "I used the following sound data in the scene:\n",
      "\n",
      "UI_Cancel\n",
      "https://freesound.org/people/unfa/sounds/565133/\n",
      "\n",
      "Success\n",
      "https://freesound.org/people/Sjonas88/sounds/538554/\n",
      "\n",
      "footstep3.mp3\n",
      "https://freesound.org/people/theredshore/sounds/83969/\n",
      "\n",
      "Keyboard Typing\n",
      "https://freesound.org/people/Trollarch2/sounds/331656/\n",
      "\n",
      "# Video ID: HVZwn9KIWiU\n",
      "\n",
      "Description:\n",
      "This is an EEVEE NEXT version of https://youtu.be/zQEbJUg8r9o\n",
      "\n",
      "# Video ID: W05RhCUnlH4\n",
      "\n",
      "Description:\n",
      "3DCG animation rendered with Blender's EEVEE engine.\n",
      "\n",
      "Audio: https://en.wikipedia.org/wiki/File:Johann_Sebastian_Bach_Prelude_in_A_minor_BWV_543_Robert_K%C3%B6bler_Silbermann-Organ.mp3\n",
      "\n",
      "Background: https://polyhaven.com/a/zwinger_night\n",
      "\n",
      "# Video ID: ICZHSJ5eQME\n",
      "\n",
      "Description:\n",
      "An eVTOL prototype made with Blender.\n",
      "\n",
      "https://github.com/araobp/blender-3d/\n",
      "\n",
      "HDRI: https://polyhaven.com/a/spruit_sunrise\n",
      "Drone sound: https://freesound.org/people/Trebblofang/sounds/176004/\n",
      "Background sound: https://freesound.org/people/burgersmoke/sounds/642005/\n",
      "\n",
      "# Video ID: wX6leJTcHME\n",
      "\n",
      "Description:\n",
      "Audio file: https://commons.wikimedia.org/wiki/File:Bach_C_Major_Prelude_Equal.ogg\n",
      "\n",
      "# Video ID: MoSrWDInzIg\n",
      "\n",
      "Description:\n",
      "This video is an EEVEE-version of this video: https://youtu.be/xugC3eSykPA.\n",
      "\n",
      "I admit that the previous one rendered with Cycle is better than this one, but EEVEE is very fast!\n",
      "\n",
      "This is a 3DCG animation made with Blender and MakeHuman. I played the piano myself to record the BGM (BWV846).\n",
      "\n",
      "https://github.com/araobp/blender-3d/scenes/\n",
      "\n",
      "MakeHuman: http://www.makehumancommunity.org/\n",
      "\n",
      "Credits:\n",
      "\n",
      "I have used MakeHuman extensions, \"High heels\" and \"Nails\", from the following pages:\n",
      "\n",
      "High heels: http://www.makehumancommunity.org/clothes/high_heels_library.html\n",
      "Nails: http://www.makehumancommunity.org/clothes/mind_nails_02_medium.html\n",
      "\n",
      "I have also used a HDRI asset from the following page:\n",
      "\n",
      "https://polyhaven.com/a/dresden_square\n",
      "\n",
      "# Video ID: 1Ucw4LMh3Ow\n",
      "\n",
      "Description:\n",
      "An eVTOL prototype made with Blender.\n",
      "\n",
      "https://github.com/araobp/blender-3d/\n",
      "\n",
      "Credit: the background HDRI image is from https://polyhaven.com/a/noon_grass\n",
      "\n",
      "# Video ID: OWIU_BMA92s\n",
      "\n",
      "Description:\n",
      "2D DCT explained\n",
      "\n",
      "# Video ID: bS-bzMsygZQ\n",
      "\n",
      "Description:\n",
      "This is a digital twin of my edge AI toy that I developed in 2019: https://youtube.com/shorts/d6OYSllaVEs?si=C2SNGSqgbrIVoqH2\n",
      "\n",
      "The toy uses AMG8833 from Panasonic to capture 8x8 matrix heatmap, calculate coefficients of Discrete Cosine Transform Type-II (DCT Type-II ) from the heatmap, drop the higher frequency coefficients, then input the rest of the coefficients to Dense Neural Network (DNN) for inference. Its accuracy is surprisingly good!\n",
      "\n",
      "The latest working code with the latest CubeIDE and STM32Cube.AI is in this project: https://github.com/araobp/edge-ai\n",
      "\n",
      "# Video ID: e6F0C5PsM-8\n",
      "\n",
      "Description:\n",
      "This is a digital twin of my edge AI toy that I developed in 2019: https://youtube.com/shorts/d6OYSllaVEs?si=C2SNGSqgbrIVoqH2\n",
      "\n",
      "The toy uses AMG8833 from Panasonic to capture 8x8 matrix heatmap, calculate coefficients of Discrete Cosine Transform Type-II (DCT Type-II ) from the heatmap, drop the higher frequency coefficients, then input the rest of the coefficients to Dense Neural Network (DNN) for inference. Its accuracy is surprisingly good!\n",
      "\n",
      "The latest working code with the latest CubeIDE and STM32Cube.AI is in this project: https://github.com/araobp/edge-ai\n",
      "\n",
      "# Video ID: WKvi7je3oDE\n",
      "\n",
      "Description:\n",
      "Moon satellite view made with Blender.\n",
      "\n",
      "Its texture data is from NASA.\n",
      "\n",
      "# Video ID: N-dCsRtM6n0\n",
      "\n",
      "Description:\n",
      "All the 3D models (excluding the high heels) and animations were created by me with Blender.\n",
      "\n",
      "This is my first walk cycle animation. This scene was rendered with Blender's Eevee engine.\n",
      "\n",
      "Credits:\n",
      "\n",
      "The walking woman was generated by Makehuman. I made some modifications on its mesh, shaders etc. I applied Rigify to the model to make animations.\n",
      "\n",
      "All the PBR materials in the scene are from AmbientCG\n",
      "\n",
      "I used MakeHuman extensions, \"High heels\", from the following pages: http://www.makehumancommunity.org/clothes/high_heels_library.html\n",
      "\n",
      "I used the following sound sources from freesound.org:\n",
      "- [Girl walking in heels.wav](https://freesound.org/people/CyrileneRossouw/sounds/407564/)\n",
      "- [success.wav](https://freesound.org/people/grunz/sounds/109662/)\n",
      "- [Elevator door 06.wav](https://freesound.org/people/LG/sounds/73122/)\n",
      "\n",
      "# Video ID: 9N4XoviSjys\n",
      "\n",
      "Description:\n",
      "This is a 3DCG drone flying animation with HDRI and a photo background, made with Blender.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/hdri\n",
      "\n",
      "# Video ID: xugC3eSykPA\n",
      "\n",
      "Description:\n",
      "This is a 3DCG animation made with Blender and MakeHuman. I played the piano myself to record the BGM (BWV846).\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/scenes\n",
      "\n",
      "MakeHuman: http://www.makehumancommunity.org/\n",
      "\n",
      "Credits:\n",
      "\n",
      "I have used MakeHuman extensions, \"High heels\" and \"Nails\", from the following pages:\n",
      "\n",
      "High heels: http://www.makehumancommunity.org/clothes/high_heels_library.html\n",
      "Nails: http://www.makehumancommunity.org/clothes/mind_nails_02_medium.html\n",
      "\n",
      "I have also used a HDRI asset from the following page:\n",
      "\n",
      "https://polyhaven.com/a/dresden_square\n",
      "\n",
      "# Video ID: zQEbJUg8r9o\n",
      "\n",
      "Description:\n",
      "This is a 3DCG animation made with Blender and MakeHuman.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/scenes\n",
      "\n",
      "MakeHuman: http://www.makehumancommunity.org/\n",
      "\n",
      "Credits:\n",
      "\n",
      "I have used MakeHuman extensions, \"High heels\" and \"Nails\", from the following pages:\n",
      "\n",
      "High heels: http://www.makehumancommunity.org/clothes/high_heels_library.html\n",
      "Nails: http://www.makehumancommunity.org/clothes/mind_nails_02_medium.html\n",
      "\n",
      "# Video ID: 1xmiIczxZqo\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/tools\n",
      "\n",
      "# Video ID: fQNP2FG3s7k\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/robots\n",
      "\n",
      "# Video ID: DVG4slg7Q_Y\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/robots\n",
      "\n",
      "# Video ID: F15Zp4pqwVk\n",
      "\n",
      "Description:\n",
      "Made with Blender\n",
      "\n",
      "# Video ID: C_qCqOBFJzs\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-3d/tree/main/robots\n",
      "\n",
      "# Video ID: fLw5PB_CiDo\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-science/tree/main/Physics\n",
      "\n",
      "# Video ID: VYyuJVpb2LU\n",
      "\n",
      "Description:\n",
      "Made with Blender.\n",
      "\n",
      "I used MacBook Air for rendering this scene.\n",
      "\n",
      "https://github.com/araobp/blender-science/tree/main/Physics\n",
      "\n",
      "# Video ID: b3r3MgwXIK0\n",
      "\n",
      "Description:\n",
      "A short animation made with Blender by me.\n",
      "\n",
      "# Video ID: U4oGypuHEh0\n",
      "\n",
      "Description:\n",
      "An animation to explain how API integration works, made with Blender\n",
      "\n",
      "# Video ID: zWdhYGzhVPs\n",
      "\n",
      "Description:\n",
      "I used to use Blender and Unity for making animations, but this time is Blender only. \n",
      "\n",
      "In the animation , I used a 3D model from this IFC BIM archives: http://openifcmodel.cs.auckland.ac.nz/\n",
      "\n",
      "# Video ID: vBHXwXxKi4s\n",
      "\n",
      "Description:\n",
      "A woman is walking in Azuma House.\n",
      "\n",
      "This scene is made with Blender and Unity.\n",
      "\n",
      "IFC BIM of the house is from this site:\n",
      "http://openifcmodel.cs.auckland.ac.nz\n",
      "\n",
      "# Video ID: BFTbxZobyvY\n",
      "\n",
      "Description:\n",
      "This short movie is to explane how IFC BIM can be rendered in my original AR app:\n",
      "https://github.com/araobp/unity-ar\n",
      "\n",
      "I downloaded \"FZK Haus\" from the following BIM archive:\n",
      "http://openifcmodel.cs.auckland.ac.nz\n",
      "\n",
      "Then I modified the original FZK Haus IFC BIM with Blender (with BlenderBIM add-on) for my AR app:\n",
      "- modified some parts to make them look better\n",
      "- added CC0Texture to some faces\n",
      "- added a piano chair\n",
      "- etc\n",
      "\n",
      "# Video ID: IXSC8B0Yoos\n",
      "\n",
      "Description:\n",
      "Made with Unity\n",
      "\n",
      "# Video ID: xICYinJU3u4\n",
      "\n",
      "Description:\n",
      "A short demo video made with Unity\n",
      "\n",
      "# Video ID: 3EMcrRJ446w\n",
      "\n",
      "Description:\n",
      "A construction operation simulation in a pneumatic caisson.\n",
      "\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: NR9jN1WamqI\n",
      "\n",
      "Description:\n",
      "\n",
      "\n",
      "# Video ID: mACBBLufDp0\n",
      "\n",
      "Description:\n",
      "It is a demo video of game streaming with Unity Render Streaming.\n",
      "\n",
      "# Video ID: CTrM93eaq1s\n",
      "\n",
      "Description:\n",
      "I have just evaluated Unity Render Streaming.\n",
      "\n",
      "https://github.com/araobp/unity-excavator/blob/master/doc/RenderStreaming.md\n",
      "\n",
      "# Video ID: ytygJGUO5nM\n",
      "\n",
      "Description:\n",
      "The movie is made with Unity.\n",
      "\n",
      "https://github.com/araobp/unity-humanoid\n",
      "\n",
      "# Video ID: um-spiRzK4k\n",
      "\n",
      "Description:\n",
      "The movie is made with Unity.\n",
      "\n",
      "https://github.com/araobp/unity-humanoid\n",
      "\n",
      "# Video ID: gcNkXm_A9H8\n",
      "\n",
      "Description:\n",
      "The movie is made with Unity.\n",
      "\n",
      "https://github.com/araobp/unity-humanoid\n",
      "\n",
      "# Video ID: cl6UpGPZEys\n",
      "\n",
      "Description:\n",
      "The movie is made with Unity.\n",
      "\n",
      "https://github.com/araobp/unity-humanoid\n",
      "\n",
      "# Video ID: Is45dRC3fNM\n",
      "\n",
      "Description:\n",
      "Total Station simulation on Unity.\n",
      "\n",
      "It uses Raycast instead of a laser measuring tool and calculates coordinates at prisms based on Triangulation.\n",
      "\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: 5SQ1QVdskcI\n",
      "\n",
      "Description:\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: 2z0K-X5a5Ss\n",
      "\n",
      "Description:\n",
      "Solar system simulation on Unity.\n",
      "\n",
      "Rigidbody's Gravity was replaced with G * M * m / r ^ 2 for this simulation.\n",
      "\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: 2AjkpGLnm74\n",
      "\n",
      "Description:\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: 0X4c5gxU6-A\n",
      "\n",
      "Description:\n",
      "Excavator simulation on Unity.\n",
      "\n",
      "https://github.com/araobp/unity-excavator\n",
      "\n",
      "# Video ID: UvSJ3fOOCXc\n",
      "\n",
      "Description:\n",
      "Acoustic features of various musical instruments.\n",
      "\n",
      "# Video ID: RFJgpf7kdJA\n",
      "\n",
      "Description:\n",
      "I made a model door for IoT demo back in 2017. The model uses Microchip PIC16F1825 MCU to control a servo motor and a LED, and to read output from a hall sensor. The data is transferred to Raspberry Pi 3 via USB/UART.\n",
      "\n",
      "# Video ID: 4BaBL-gmQBk\n",
      "\n",
      "Description:\n",
      "\n",
      "\n",
      "# Video ID: RV7oED41P2w\n",
      "\n",
      "Description:\n",
      "This is a screen capture of my original oscilloscope based on matplotlib/Tkinter. My original program on STM32L476RG captures raw data as 16bit PCM, converts it into Mel spectrogram as feature of thesound, then transfers the feature to Keras/TensorFlow on my PC.\n",
      "\n",
      "# Video ID: wbkjt2Bl5TY\n",
      "\n",
      "Description:\n",
      "This is a video to demonstrate musical instrument recognition based on X-CUBE-AI. The inference processing is running on STM32L476RG.\n",
      "\n",
      "# Video ID: d6OYSllaVEs\n",
      "\n",
      "Description:\n",
      "I have developed an AI-enabled \"rock-paper-scissors\" with X-CUBE-AI on STM32(arm cortex-m4) microcontroller. It uses an infrared array sensor to capture 8x8 pixels image as a heatmap. 2D DCT is applied to the image to extract features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_youtube_description(video_id, api_key):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={api_key}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'items' in data and len(data['items']) > 0:\n",
    "            description = data['items'][0]['snippet']['description']\n",
    "            return description\n",
    "        else:\n",
    "            return \"Not found.\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "for video_id in video_ids:\n",
    "        \n",
    "    description = get_youtube_description(video_id, API_KEY)\n",
    "    print(f\"# Video ID: {video_id}\\n\")\n",
    "    print(f\"Description:\\n{description}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
